{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xihua/ENV/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two useful functions: I wrote one to plot 28x28 pixel images from numpy arrays and will use one to plot the confusion matrix from the [scikit-learn documentation](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(input_array, rows=4, cols=5, title=''):\n",
    "    '''\n",
    "    Function to plot 28x28 pixel drawings that are stored in a numpy array.\n",
    "    Specify how many rows and cols of pictures to display (default 4x5).  \n",
    "    If the array contains less images than subplots selected, surplus subplots remain empty.\n",
    "    '''\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(cols,rows))\n",
    "    ax.axis('off')\n",
    "    plt.title(title)\n",
    "\n",
    "    for i in list(range(0, min(len(input_array),(rows*cols)) )):      \n",
    "        a = fig.add_subplot(rows,cols,i+1)\n",
    "        imgplot = plt.imshow(input_array[i,:784].reshape((28,28)), cmap='gray_r', interpolation='nearest')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALLOWS YOU TO SEE SAMPLES\n",
    "plot_samples(ear, title='Sample ear drawings\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING\n",
    "\n",
    "# load the data\n",
    "ear = np.load('datasets/ear.npy')\n",
    "eye = np.load('datasets/eye.npy')\n",
    "mouth = np.load('datasets/mouth.npy')\n",
    "nose = np.load('datasets/nose.npy')\n",
    "\n",
    "# add a column with labels\n",
    "ear = np.c_[ear, np.zeros(len(ear))]\n",
    "eye = np.c_[eye, np.ones(len(eye))]\n",
    "mouth = np.c_[mouth, 2*np.ones(len(mouth))]\n",
    "nose = np.c_[nose, 3*np.ones(len(nose))]\n",
    "\n",
    "# store the label codes in a dictionary\n",
    "label_dict = {0:'ear', 1:'eye', 2:'mouth', 3:'nose'}\n",
    "\n",
    "#PREPARE DATA FOR SCIKIT-LEARN\n",
    "\n",
    "X = np.concatenate((ear[:72500,:-1], eye[:72500,:-1], mouth[:72500,:-1], nose[:72500,:-1]), axis=0).astype('float32') # all columns but the last\n",
    "y = np.concatenate((ear[:72500,-1], eye[:72500,-1], mouth[:72500,-1], nose[:72500,-1]), axis=0).astype('float32') # the last column\n",
    "\n",
    "# train/test split (divide by 255 to obtain normalized values between 0 and 1)\n",
    "# I will use a 50:50 split, since I want to start by training the models on 5'000 samples and thus have plenty of samples to spare for testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X/255.,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ear0=ear[0:1,:-1]/255.\n",
    "eye0=eye[0:1,:-1]/255.\n",
    "mouth0=mouth[0:1,:-1]/255.\n",
    "nose0=nose[0:1,:-1]/255.\n",
    "print np.shape(X_train[0])\n",
    "print np.shape(ear0)\n",
    "init_c = np.vstack((ear0,eye0,mouth0,nose0))\n",
    "print np.shape(init_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=4, init = init_c, random_state=0).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = kmeans.labels_\n",
    "c = kmeans.cluster_centers_\n",
    "print np.shape(l)\n",
    "print np.shape(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = mouth[7:8,:-1]/255\n",
    "kmeans.predict(sample)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [0,0,0,0]\n",
    "for i in range(20000,20625):\n",
    "    j = i + 1\n",
    "    #to read in a sample, divide by 255\n",
    "    sample = mouth[i:j,:-1]/255\n",
    "    #print np.shape(sample)\n",
    "    sample_pred = int(kmeans.predict(sample)[0])\n",
    "    count = preds[sample_pred]\n",
    "    preds[sample_pred] += 1\n",
    "    if count < 3:\n",
    "        outfile = \"kmeans/mouth_\" + str(i) + \"_\" + str(int(sample_pred)) + \".png\"\n",
    "        imgplot = plt.imshow(sample.reshape((28,28)), cmap='gray_r', interpolation='nearest')\n",
    "        plt.savefig(outfile)\n",
    "print preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING\n",
    "\n",
    "# load the data\n",
    "ear = np.load('datasets/ear.npy')\n",
    "eye = np.load('datasets/eye.npy')\n",
    "mouth = np.load('datasets/mouth.npy')\n",
    "nose = np.load('datasets/nose.npy')\n",
    "\n",
    "# add a column with labels\n",
    "ear = np.c_[ear, np.zeros(len(ear))]\n",
    "eye = np.c_[eye, np.ones(len(eye))]\n",
    "mouth = np.c_[mouth, 2*np.ones(len(mouth))]\n",
    "nose = np.c_[nose, 3*np.ones(len(nose))]\n",
    "\n",
    "# store the label codes in a dictionary\n",
    "label_dict = {0:'ear', 1:'eye', 2:'mouth', 3:'nose'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARE DATA FOR SCIKIT-LEARN\n",
    "\n",
    "X = np.concatenate((ear[:72500,:-1], eye[:72500,:-1], mouth[:72500,:-1], nose[:72500,:-1]), axis=0).astype('float32') # all columns but the last\n",
    "y = np.concatenate((ear[:72500,-1], eye[:72500,-1], mouth[:72500,-1], nose[:72500,-1]), axis=0).astype('float32') # the last column\n",
    "\n",
    "# train/test split (divide by 255 to obtain normalized values between 0 and 1)\n",
    "# I will use a 50:50 split, since I want to start by training the models on 5'000 samples and thus have plenty of samples to spare for testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X/255.,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "#RUN KNN ALGORITHM\n",
    "clf_knn = KNeighborsClassifier(n_neighbors = 4,n_jobs=-1)\n",
    "clf_knn.fit(X_train, y_train)\n",
    "y_pred_knn = clf_knn.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print ('KNN accuracy: ',acc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET INDIVIDUAL PREDICTIVE SCORE\n",
    "#read in data file or choose one:\n",
    "print np.shape(X_test)\n",
    "print np.shape(y_pred_knn)\n",
    "test_sample = X_test[0:1]\n",
    "print np.shape(test_sample)\n",
    "test_pred = clf_knn.predict(test_sample)\n",
    "print test_pred\n",
    "imgplot = plt.imshow(test_sample.reshape((28,28)), cmap='gray_r', interpolation='nearest')\n",
    "plt.savefig(\"test.png\")\n",
    "print np.shape(ear[:12500,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = 0\n",
    "for i in range(20000,20625):\n",
    "    j = i + 1\n",
    "    #to read in a sample, divide by 255\n",
    "    sample = mouth[i:j,:-1]/255\n",
    "    #print np.shape(sample)\n",
    "    sample_pred = clf_knn.predict(sample)\n",
    "    if not(sample_pred == 2):\n",
    "        errors += 1\n",
    "        #print i, sample_pred\n",
    "        #if errors <= 25:\n",
    "            #outfile = \"knnerrors/nose_\" + str(i) + \"_\" + str(int(sample_pred[0])) + \".png\"\n",
    "            #imgplot = plt.imshow(sample.reshape((28,28)), cmap='gray_r', interpolation='nearest')\n",
    "            #plt.savefig(outfile)\n",
    "print errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out a Convolutional Neural Network (CNN) with Keras. I will use a model from this [tutorial](http://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/) by Jason Brownlee. It has the following 9 layers:\n",
    "\n",
    "1. Convolutional layer with 30 feature maps of size 5×5. \n",
    "2. Pooling layer taking the max over 2*2 patches. \n",
    "3. Convolutional layer with 15 feature maps of size 3×3.\n",
    "4. Pooling layer taking the max over 2*2 patches.\n",
    "5. Dropout layer with a probability of 20%. \n",
    "6. Flatten layer. \n",
    "7. Fully connected layer with 128 neurons and rectifier activation. \n",
    "8. Fully connected layer with 50 neurons and rectifier activation. \n",
    "9. Output layer.\n",
    "\n",
    "Keras requires one hot encoding of the y labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the CNN model\n",
    "def cnn_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58000, 1, 28, 28)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2f427a9ecffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_cnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "print np.shape(X_test_cnn)\n",
    "print np.shape(y_pred_cnn)\n",
    "test_sample = X_test_cnn[0:1]\n",
    "print np.shape(test_sample)\n",
    "test_pred = model.predict_classes(test_sample, verbose=0)\n",
    "print test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "CNN CODE : Preprocessing for Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA PREPROCESSING\n",
    "\n",
    "# load the data\n",
    "ear = np.load('datasets/ear.npy')\n",
    "eye = np.load('datasets/eye.npy')\n",
    "mouth = np.load('datasets/mouth.npy')\n",
    "nose = np.load('datasets/nose.npy')\n",
    "\n",
    "# add a column with labels\n",
    "ear = np.c_[ear, np.zeros(len(ear))]\n",
    "eye = np.c_[eye, np.ones(len(eye))]\n",
    "mouth = np.c_[mouth, 2*np.ones(len(mouth))]\n",
    "nose = np.c_[nose, 3*np.ones(len(nose))]\n",
    "\n",
    "# store the label codes in a dictionary\n",
    "label_dict = {0:'ear', 1:'eye', 2:'mouth', 3:'nose'}\n",
    "\n",
    "#PREPARE DATA FOR SCIKIT-LEARN\n",
    "\n",
    "X = np.concatenate((ear[:72500,:-1], eye[:72500,:-1], mouth[:72500,:-1], nose[:72500,:-1]), axis=0).astype('float32') # all columns but the last\n",
    "y = np.concatenate((ear[:72500,-1], eye[:72500,-1], mouth[:72500,-1], nose[:72500,-1]), axis=0).astype('float32') # the last column\n",
    "\n",
    "# train/test split (divide by 255 to obtain normalized values between 0 and 1)\n",
    "# I will use a 50:50 split, since I want to start by training the models on 5'000 samples and thus have plenty of samples to spare for testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X/255.,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train_cnn = np_utils.to_categorical(y_train)\n",
    "y_test_cnn = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test_cnn.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train_cnn = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# build the model\n",
    "model = cnn_model()\n",
    "# Fit the model\n",
    "model.fit(X_train_cnn, y_train_cnn, validation_data=(X_test_cnn, y_test_cnn), epochs=30, batch_size=100)\n",
    "#save the model\n",
    "model.save(\"checkpoint/checkpoint_300K.h5\")\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_model()\n",
    "model = load_model(\"checkpoint/checkpoint_300K.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the CNN with Keras performed best.\n",
    "\n",
    "Let's take a look at the predictions of the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
    "print('Final CNN accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.shape(X_test_cnn)\n",
    "test_sample = X_test_cnn[0:1]\n",
    "print np.shape(test_sample)\n",
    "test_pred = model.predict_classes(test_sample)\n",
    "test_pred = model.predict(test_sample)\n",
    "conf = max(test_pred[0])\n",
    "print test_pred\n",
    "print conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 7, 0, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neer/APa1N6VjlDHGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = [0,0,0,0]\n",
    "for i in range(20000,20625):\n",
    "    j = i + 1\n",
    "    #to read in a sample, divide by 255\n",
    "    sample = mouth[i:j,:-1]/255\n",
    "    sample = np.reshape(sample,(1,1,28,28))\n",
    "    #print np.shape(sample)\n",
    "    sample_pred = model.predict_classes(sample,verbose=0)\n",
    "    if not(sample_pred == 2):\n",
    "        errors[int(sample_pred)] = errors[int(sample_pred)] + 1\n",
    "        #print i, sample_pred\n",
    "        if sum(errors) <= 5:\n",
    "            outfile = \"cnnerrors/mouth_\" + str(i) + \"_\" + str(int(sample_pred[0])) + \".png\"\n",
    "            imgplot = plt.imshow(sample.reshape((28,28)), cmap='gray_r', interpolation='nearest')\n",
    "            plt.savefig(outfile)\n",
    "print errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred_cnn)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['dog','octopus','bee','hedgehog','giraffe'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what probabilities were predicted by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_probab = model.predict(X_test_cnn, batch_size=32, verbose=0)\n",
    "\n",
    "# extract the probability for the label that was predicted:\n",
    "p_max = np.amax(cnn_probab, axis=1)\n",
    "\n",
    "plt.hist(p_max, normed=True, bins=list(np.linspace(0,1,11)));\n",
    "plt.xlabel('p of predicted class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For about 70% of the pictures, the CNN predicted the label with > 90% certainty.\n",
    "\n",
    "If the predictions of the CNN are well calibrated, the average prediction certainty should be equal to the accuracy (90%), which is indeed the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(p_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest certainty of a prediction is about 25%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(p_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some predictions in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,15))\n",
    "\n",
    "for i in list(range(10)):\n",
    "\n",
    "    # plot probabilities:\n",
    "    ax = plt.subplot2grid((10, 5), (i, 0), colspan=4);\n",
    "    plt.bar(np.arange(5), cnn_probab[i], 0.35, align='center');\n",
    "    plt.xticks(np.arange(5), ['dog','octopus','bee','hedgehog','giraffe'])\n",
    "    plt.tick_params(axis='x', bottom='off', top='off')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.ylim(0,1)\n",
    "    plt.subplots_adjust(hspace = 0.5)\n",
    "\n",
    "    # plot picture:\n",
    "    ax = plt.subplot2grid((10, 5), (i, 4));\n",
    "    plt.imshow(X_test[i].reshape((28,28)),cmap='gray_r', interpolation='nearest');\n",
    "    plt.xlabel(label_dict[y_test[i]]); # get the label from the dict\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at some pictures where the CNN was very unsure about the label by filtering with [p_max<0.4]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,15))\n",
    "\n",
    "for i in list(range(10)):\n",
    "    \n",
    "    # plot probabilities:\n",
    "    ax = plt.subplot2grid((10, 5), (i, 0), colspan=4);\n",
    "    plt.bar(np.arange(5), cnn_probab[p_max<0.4][i], 0.35, align='center');\n",
    "    plt.xticks(np.arange(5), ['dog','octopus','bee','hedgehog','giraffe'])\n",
    "    plt.tick_params(axis='x', bottom='off', top='off')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.ylim(0,1)\n",
    "    plt.subplots_adjust(hspace = 0.5)\n",
    "\n",
    "    # plot picture:\n",
    "    ax = plt.subplot2grid((10, 5), (i, 4));\n",
    "    plt.imshow(X_test[p_max<0.4][i].reshape((28,28)),cmap='gray_r', interpolation='nearest');\n",
    "    plt.xlabel(label_dict[y_test[p_max<0.4][i]]); # get the label from the dict\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is still some room for improvement. Notably, I have used just about 2% of the pictures for training. By increasing that number, big increases in accuracy would certainly be possible."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
